\begin{comment}
	- CNN approaches
	- R-CNN - fast - faster
	- SSD
	- R-FCN
	- YOLO (speed)	
\end{comment}

\section{Related Work}
One of the first methods to show that \glspl{cnn} could significantly improve object detection was that of R-CNN \cite{rcnn}. The method obtains the name R-CNN based upon a \gls{cnn} is used on regions of the image. Many earlier object detection approaches were used in a sliding window fashion testing all areas of an image. This can lead to a huge amount of potential testing windows especially if the object detection is done at a multitude of different scales. The method was heavily inspired by the AlexNet model that started the deep learning renaissance in 2012 by winning classification challenge in the \gls{ilsvrc}. The authors of R-CNN aimed to show that the advances in classification with a model such as AlexNet could also be done in object detection. In R-CNN the model is used as a feature extractor from which a class-specific linear \gls{svm} can be trained on top of. The AlexNet-based feature extractor is firstly pre-trained on a large dataset designed for classification, in this case the training set from \gls{ilsvrc} 2012. This pre-trained model is then adapted to the new domain of object detection by fine-tuning the model accordingly. In this instance the authors fine-tuned warped training instances from the \gls{pascalvoc} dataset. The AlexNet model was also altered to classify the 20 classes present in \gls{pascalvoc} rather than the 1000 classes in \gls{ilsvrc}. The pipeline of the R-CNN is split into 3 modules:

\begin{enumerate}
	\item Region proposals.
	\item Feature extraction.
	\item Class-specific linear \glspl{svm}.
\end{enumerate}

In this first module, region proposal, there is a large number of choices of methods to produce a suitable number of windows in comparison to a sliding window approach. R-CNN is agnostic to the region proposal method chosen and in the original work SelectiveSearch \cite{selectivesearch} is used. Module two, as explained earlier, is the use of a \gls{cnn} as a feature extractor. This is in the form of a 4096-dimensional feature vector from the domain-specific \gls{pascalvoc} trained AlexNet model. These feature vectors are used in the third module, class-specific linear \glspl{svm}. In the case of \gls{pascalvoc} a total of 21 \glspl{svm} are trained, one for each of the 20 classes in the challenge and one for a background class. The training of the \glspl{svm} is done by forward propagating a large number of both positive and negative region proposals found with SelectiveSearch and storing each 4096-dimensional feature vector to disk. After this the appropriate labels are applied to each vector and a linear \gls{svm} is optimised for the 21 classes. At test time, for a given image SelectiveSearch is used to produce around 2000 proposals. Each of the proposals are propagated through the network to extract their respective feature vectors. Each feature vector is then tested against every \gls{svm} to produce a score for each class. Finally greedy \gls{nms} is applied to remove overlapping detections. The approach outlined in R-CNN produced a significant improvement in object detection with an improvement of roughly 13\%, compared to previous state-of-the-art methods, to an overall 53.7\% \gls{map} on the \gls{pascalvoc} 2010 test set. Similar results were also found on the \gls{pascalvoc} 2011/12 set with \gls{map} of 53.5\%. Despite the significant improvements with a \gls{cnn}-based method on region proposals there are still issues with the R-CNN. Firstly, the testing time per image is very slow at roughly 47 seconds on an Nvidia K40 GPU. Also extracting features for each proposal in order to train the \glspl{svm} takes a large amount of disk space and may not be feasible on all hardware configurations. Finally, as the R-CNN is made up of 3 modules the training is done in a multi-stage manner rather than end-to-end. Therefore, the loss calculating when optimising the \glspl{svm} are not used to update the \gls{cnn} parameters.

Fast R-CNN - speed and classifies with the CNN meaning loss at classification is used in backpropagation.