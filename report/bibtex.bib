@article{zhang,
 author = {Zhang, Xin and Yang, Yee-Hong and Han, Zhiguang and Wang, Hui and Gao, Chao},
 title = {Object Class Detection: A Survey},
 journal = {ACM Comput. Surv.},
 issue_date = {October 2013},
 volume = {46},
 number = {1},
 month = jul,
 year = {2013},
 issn = {0360-0300},
 pages = {10:1--10:53},
 articleno = {10},
 numpages = {53},
 url = {http://doi.acm.org/10.1145/2522968.2522978},
 doi = {10.1145/2522968.2522978},
 acmid = {2522978},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Object class detection, appearance model, categorization, evaluation, intra-class appearance variation, segmentation, social images},
} 

@misc{pascalvoc2012,
author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
title = "The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults",
howpublished = "http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html"
}

@article{imagenet,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@Inbook{mscoco,
author="Lin, Tsung-Yi
and Maire, Michael
and Belongie, Serge
and Hays, James
and Perona, Pietro
and Ramanan, Deva
and Doll{\'a}r, Piotr
and Zitnick, C. Lawrence",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Microsoft COCO: Common Objects in Context",
bookTitle="Computer Vision -- ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="740--755",
isbn="978-3-319-10602-1",
doi="10.1007/978-3-319-10602-1_48",
url="http://dx.doi.org/10.1007/978-3-319-10602-1_48"
},

@book{schroff,
  title={Semantic Image Segmentation and Web-supervised Visual Learning},
  author={Schroff, F.},
  url={https://books.google.dk/books?id=4EqZYgEACAAJ},
  year={2009},
  publisher={University of Oxford}
}

@inproceedings{rcnn,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}


@incollection{alexnet,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@Article{selectivesearch,
author="Uijlings, J. R. R.
and van de Sande, K. E. A.
and Gevers, T.
and Smeulders, A. W. M.",
title="Selective Search for Object Recognition",
journal="International Journal of Computer Vision",
year="2013",
volume="104",
number="2",
pages="154--171",
abstract="This paper addresses the problem of generating possible object locations for use in object recognition. We introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our selective search results in a small set of data-driven, class-independent, high quality locations, yielding 99Â {\%} recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The selective search software is made publicly available (Software:                   http://disi.unitn.it/{\textasciitilde}uijlings/SelectiveSearch.html                                  ).",
issn="1573-1405",
doi="10.1007/s11263-013-0620-5",
url="http://dx.doi.org/10.1007/s11263-013-0620-5"
}

@inproceedings{fastrcnn,
  Author = {Ross Girshick},
  Title = {Fast {R-CNN}},
  Booktitle = {Proceedings of the International
               Conference on Computer Vision ({ICCV})},
  Year = {2015}
}

@inproceedings{fasterrcnn,
  Author = {Shaoqing Ren and Kaiming He and
            Ross Girshick and Jian Sun},
  Title = {Faster {R-CNN}: Towards Real-Time Object Detection
           with Region Proposal Networks},
  Booktitle = {Neural Information Processing Systems ({NIPS})},
  Year = {2015}
}




